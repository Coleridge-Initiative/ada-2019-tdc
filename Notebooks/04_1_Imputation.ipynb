{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"./images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ghani, Rayid, Frauke Kreuter, Julia Lane, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Brian Kim, Avishek Kumar, Jonathan Morgan, Ursula Kaczmarek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome measurement and imputation\n",
    "### Learning Objectives\n",
    "\n",
    "* Gain understanding of the concept of measurement error in the context of a cohort's earnings\n",
    "\n",
    "* Explore options for imputing missing values\n",
    "\n",
    "* Visualize estimate changes following imputation\n",
    "\n",
    "\n",
    "To determine the outcome of employment earnings for members of our 2014 Q4 TANF cohort, we need to decide what to do when earnings data is missing. Earnings may be missing for any number of reasons. The cohort member may have found work outside Indiana or Illinois, the QCEW may not report the member's earnings, or the member may not be receiving any earnings in the given time period. \n",
    "\n",
    "In this notebook, we explore the resulting earnings outcomes for three points in time after leaving TANF. Outcomes are calculated one quarter later, two quarters later, and one year later, and we will compare earnings distributions when (a) dropping missing values, (b) setting missing values to zero, (c) imputing missing values as the mean for the overall cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Python Setup and Database Connection](#Python-Setup-and-Database-Connection)\n",
    "\n",
    "- [Pull the Cohort Data](#Pull-the-Cohort-Data)\n",
    "\n",
    "- [Isolate Missing Earnings Cases](#Isolate-Missing-Earnings-Cases)\n",
    "\n",
    "- [Explore Earnings Estimates Before Imputation](#Explore-Earnings-Estimates-Before-Imputation)\n",
    "\n",
    "- [Impute Wage Values](#Impute-Wage-Values)\n",
    "\n",
    "- [Compare Distributions Through Visualization](#Compare-Distributions-Through-Visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup and Database Connection\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Before we begin, run the code cell below to initialize the libraries. We're already familiar with `matplotlib`, `pandas`, and `psycopg2` from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up sqlalchemy engine\n",
    "host = 'stuffed.adrf.info'\n",
    "DB = 'appliedda'\n",
    "\n",
    "connection_string = \"postgresql://{}/{}\".format(host, DB)\n",
    "conn = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull the Cohort Data\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "\n",
    "Our cohort consists of Indiana and Illinois TANF recipients who had a spell end sometime in Q4 of 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp table of all cohort members\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS cohort_2014;\n",
    "\n",
    "CREATE TEMP TABLE cohort_2014 AS\n",
    "-- Illinois cohort members\n",
    "SELECT DISTINCT ON (m.ssn_hash) ssn_hash AS member_ssn, 17 AS state, \n",
    "    '2014-10-1'::date as end_yr_q, m.sex::text AS gender\n",
    "FROM il_dhs.indcase_spells i, il_dhs.member_relation r, il_dhs.member m\n",
    "WHERE i.recptno = r.recptno AND i.ch_dpa_caseid = r.ch_dpa_caseid \n",
    "AND i.recptno = m.recptno AND i.ch_dpa_caseid = m.ch_dpa_caseid\n",
    "AND i.end_date BETWEEN '2014-10-01'::DATE AND '2014-12-31'::DATE \n",
    "AND i.benefit_type = 'tanf46'\n",
    "AND r.reltogte = 82\n",
    "\n",
    "-- Indiana cohort members\n",
    "UNION ALL \n",
    "SELECT DISTINCT ON (ssn) ssn AS member_ssn, 18 AS state, \n",
    "    '2014-10-1'::date as end_yr_q, gender\n",
    "FROM in_fssa.person_month \n",
    "WHERE tanf_end_date::DATE BETWEEN '2014-10-01'::DATE AND '2014-12-31'::DATE\n",
    "AND tanf = 1\n",
    "AND affil = '1';\n",
    "\n",
    "COMMIT;\n",
    "\"\"\"\n",
    "conn.execute(query)\n",
    "\n",
    "# report how long creating this table took\n",
    "print('query ran in {:.2f} seconds'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many members comprise our cohort\n",
    "cohort = pd.read_sql('SELECT * FROM cohort_2014', conn)\n",
    "cohort['member_ssn'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull earnings data\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "First, let's pull the earnings data for the next quarter (2015q1), and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all earnings data for 2015Q1\n",
    "start_time = time.time()\n",
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS cohort_earnings_q1;\n",
    "\n",
    "CREATE TEMP TABLE cohort_earnings_q1 AS\n",
    "-- Illinois earnings\n",
    "SELECT ssn, 17 as state, ein, wage AS earnings\n",
    "FROM il_des_kcmo.il_wage\n",
    "WHERE year = 2015 AND quarter = 1 \n",
    "    AND ssn IN (SELECT member_ssn FROM cohort_2014)\n",
    "\n",
    "UNION ALL\n",
    "-- Indiana earnings\n",
    "SELECT ssn, 18 as state, fein AS ein, wages AS earnings\n",
    "FROM in_dwd.wage_by_employer\n",
    "WHERE year = 2015 AND quarter = 1 \n",
    "    AND ssn IN (SELECT member_ssn FROM cohort_2014);\n",
    "    \n",
    "COMMIT;\n",
    "\"\"\"\n",
    "conn.execute(query)\n",
    "\n",
    "# report how long creating this table took\n",
    "print('query ran in {:.2f} seconds'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a pandas dataframe and get a quick look\n",
    "query = \"\"\"\n",
    "select * from cohort_earnings_q1\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Earnings Estimates Before Imputation\n",
    "* Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Viewing summary statistics on the number of missing wage values is a useful start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of earnings records: {:,.0f}'.format(df.shape[0]))\n",
    "print('number of individuals with any earnings: {:,.0f}'.format(df['ssn'].nunique()))\n",
    "print('number of individuals missing values:{:,.0f}'\\\n",
    ".format(cohort['member_ssn'].nunique()-df['ssn'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our cohort return more than one job. How should we handle them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the overall difference between sum and average of earnings\n",
    "df.groupby('ssn')['earnings'].agg({'sum', 'mean'}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, let's calculate the **sum** of earnings for our three outcome time horizons and add the result directly in our cohort table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of [year, quarter] values we want to calculate\n",
    "year_quarter = [[2015,1] ,[2015,2] , [2015,4]]\n",
    "\n",
    "for yr, qtr in year_quarter:\n",
    "    print(yr, qtr)\n",
    "\n",
    "    query = '''\n",
    "    ALTER TABLE cohort_2014 DROP COLUMN IF EXISTS earnings{year}q{quarter};\n",
    "    commit;\n",
    "    ALTER TABLE cohort_2014 ADD COLUMN earnings{year}q{quarter} numeric;\n",
    "    commit;\n",
    "    \n",
    "    DROP TABLE IF EXISTS cohort_earnings_{year}q{quarter};\n",
    "    commit;\n",
    "\n",
    "    CREATE TEMP TABLE cohort_earnings_{year}q{quarter} AS\n",
    "    select ssn, sum(earnings) earnings\n",
    "    FROM (\n",
    "        \n",
    "        -- Illinois earnings\n",
    "        SELECT ssn, 17 as state, ein, wage AS earnings\n",
    "        FROM il_des_kcmo.il_wage\n",
    "        WHERE year = {year} AND quarter = {quarter} \n",
    "            AND ssn IN (SELECT member_ssn FROM cohort_2014)\n",
    "        UNION ALL\n",
    "        -- Indiana earnings\n",
    "        SELECT ssn, 18 as state, fein AS ein, wages AS earnings\n",
    "        FROM in_dwd.wage_by_employer\n",
    "        WHERE year = {year} AND quarter = {quarter} \n",
    "            AND ssn IN (SELECT member_ssn FROM cohort_2014)\n",
    "    ) q\n",
    "    GROUP BY 1;\n",
    "\n",
    "    COMMIT;\n",
    "    \n",
    "    UPDATE cohort_2014 a SET earnings{year}q{quarter} = b.earnings\n",
    "    FROM cohort_earnings_{year}q{quarter} b\n",
    "    WHERE a.member_ssn = b.ssn;\n",
    "    \n",
    "    commit;\n",
    "    \n",
    "    '''.format(year=yr, quarter=qtr)\n",
    "    conn.execute(query)\n",
    "    print('completed {year}q{quarter}'.format(year=yr, quarter=qtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in our cohort as \"df\"\n",
    "df = pd.read_sql('select * from cohort_2014', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint: Generating Summary Statistics</h3>\n",
    "Let's look at the distribution of earnings for our initial outcome results without any imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: you can refer to the code above for the Pandas function for simple summary stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Wage Values\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We will impute the following values as mentioned above: (a) simply dropping missing values (basically what we summarized above), (b) setting missing values to zero, (c) imputing missing values as the mean for the overall cohort, and (d) imputing missing values as the mean by gender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['earnings2015q2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute mean of the quarter's values we do have\n",
    "\n",
    "for yr,q in year_quarter:\n",
    "    # calculate the mean of this column\n",
    "    value = df['earnings{}q{}'.format(yr,q)].mean()\n",
    "    # copy initial values to a new column\n",
    "    df['earnings{}q{}_imp_mean'.format(yr,q)] = df['earnings{}q{}'.format(yr,q)]\n",
    "    # fill missing values with the mean\n",
    "    df['earnings{}q{}_imp_mean'.format(yr,q)] = df['earnings{}q{}'.format(yr,q)].fillna(value)\n",
    "\n",
    "# view results\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint: Imputing Values as zero</h3>\n",
    "\n",
    "Now let's impute \"missing\" as simply zero to compare the outcome measures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute earnings as zero\n",
    "# hint: what could you change in the code above to fill missing values with 0?\n",
    "\n",
    "for yr,q in year_quarter:\n",
    "    \n",
    "\n",
    "# view results\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally, let's calculate the mean by gender\n",
    "# we can do this by combining Pandas' \"groupby\" and \"transform\", like this:\n",
    "df.groupby('gender')['earnings2015q1'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for yr,q in year_quarter:\n",
    "    old_col = 'earnings{}q{}'.format(yr,q)\n",
    "    new_col = 'earnings{}q{}_mean_gender'.format(yr,q)\n",
    "    df[new_col] = df.groupby('gender')[old_col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Distributions Through Visualization\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We can quickly determine whether either or both imputation methods have significantly altered the pre-imputation wage distribution with visualization. Plotting side-by-side boxplots is an effective choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all distributions for 2015q1 side-by-side\n",
    "fig,ax = plt.subplots(figsize = (15, 8))\n",
    "df[['earnings2015q1', 'earnings2015q1_imp_zero', \n",
    "    'earnings2015q1_imp_mean', 'earnings2015q1_mean_gender']].\\\n",
    "boxplot(grid = False, vert = False)\n",
    "ax.set(title = 'distribution of earnings in 2015-Q1',\n",
    "       yticklabels = ['no imputation', 'imputed zero', \n",
    "                      'imputed mean', 'imputed mean by gender'],\n",
    "       xlim = (-500,11000),\n",
    "       xticks = (np.arange(0, 11000, 1000)))\n",
    "plt.annotate('Sources: IL DES, IN DWD, IL DHS, IN FSSA', \n",
    "             xy=(0.75,-0.1), xycoords=\"axes fraction\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint: Visualizing Other Quarters</h3>\n",
    "Let's replicate the graph above for the other quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all distributions for 2015q2 side-by-side\n",
    "fig,ax = plt.subplots(figsize = (15, 8))\n",
    "df[['earnings2015q2', 'earnings2015q2_imp_zero', \n",
    "    'earnings2015q2_imp_mean', 'earnings2015q2_mean_gender']].\\\n",
    "boxplot(grid = False, vert = False)\n",
    "ax.set(title = 'distribution of earnings in 2015-Q2',\n",
    "       yticklabels = ['no imputation', 'imputed zero', \n",
    "                      'imputed mean', 'imputed mean by gender'],\n",
    "       xlim = (-500,11000),\n",
    "       xticks = (np.arange(0, 11000, 1000)))\n",
    "plt.annotate('Sources: IL DES, IN DWD, IL DHS, IN FSSA', \n",
    "             xy=(0.75,-0.1), xycoords=\"axes fraction\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replicate for the Q4 values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-ada",
   "language": "python",
   "name": "py3-ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
